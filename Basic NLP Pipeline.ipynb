{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 507606,
          "status": "ok",
          "timestamp": 1527106603643,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "pH_LHafFfLSR",
        "outputId": "2386718d-dfac-4331-ffc7-1173f2e7e540"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/that-guy-\n",
            "[nltk_data]     martin/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/that-guy-martin/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "2023-02-19 21:12:09.151099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-19 21:12:09.407607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-02-19 21:12:09.407644: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-19 21:12:10.975761: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-19 21:12:10.975948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-19 21:12:10.975975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-19 21:12:12.107050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-02-19 21:12:12.107100: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-02-19 21:12:12.107127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thatguymartin-Latitude-E5440): /proc/driver/nvidia/version does not exist\n"
          ]
        }
      ],
      "source": [
        "#! pip install -q spacy \n",
        "#! pip install -q tabulate\n",
        "#! python -m spacy download en_core_web_lg\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from collections import Counter\n",
        "import spacy\n",
        "from tabulate import tabulate\n",
        "nlp = spacy.load('en_core_web_lg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lo_NT-CVpRKN"
      },
      "source": [
        "# Basic NLP pipeline\n",
        "\n",
        "\n",
        "*   Sentence tokenizer\n",
        "*   Word Tokenizer\n",
        "*   Parts of speech tagger\n",
        "*   Noun extraction\n",
        "*   Verb Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "9KDoN0TBfM5H"
      },
      "outputs": [],
      "source": [
        "text = u\"\"\"\n",
        "Dealing with textual data is very crucial so to handle these text data we need some \n",
        "basic text processing steps. Most of the processing steps covered in this section are \n",
        "commonly used in NLP and involve the combination of several steps into a single \n",
        "executable flow. This is usually referred to as the NLP pipeline. These flow \n",
        "can be a combination of tokenization, stemming, word frequency, parts of \n",
        "speech tagging, etc.\n",
        "\"\"\"\n",
        "\n",
        "sentenses = nltk.sent_tokenize(text)\n",
        "\n",
        "words = [nltk.word_tokenize(s) for s in sentenses]\n",
        "\n",
        "tagged_wt = [nltk.pos_tag(w)for w in words]\n",
        "\n",
        "patternPOS= []\n",
        "for tag in tagged_wt:\n",
        "  patternPOS.append([v for k,v in tag])\n",
        "  \n",
        "nouns = []  \n",
        "for tag in tagged_wt:\n",
        "  nouns.append([k for k,v in tag if v in ['NN','NNS','NNP','NNPS']])\n",
        "\n",
        "\n",
        "verbs = []  \n",
        "for tag in tagged_wt:\n",
        "  verbs.append([k for k,v in tag if v in ['VB','VBD','VBG','VBN','VBP','VBZ']])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 884,
          "status": "ok",
          "timestamp": 1527106776910,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "7s7Vh8mDOjsY",
        "outputId": "de813de0-c384-4d1c-8c89-42a20345d457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentences are: ['\\nDealing with textual data is very crucial so to handle these text data we need some \\nbasic text processing steps.', 'Most of the processing steps covered in this section are \\ncommonly used in NLP and involve the combination of several steps into a single \\nexecutable flow.', 'This is usually referred to as the NLP pipeline.', 'These flow \\ncan be a combination of tokenization, stemming, word frequency, parts of \\nspeech tagging, etc.']\n",
            "Words are:  [['Dealing', 'with', 'textual', 'data', 'is', 'very', 'crucial', 'so', 'to', 'handle', 'these', 'text', 'data', 'we', 'need', 'some', 'basic', 'text', 'processing', 'steps', '.'], ['Most', 'of', 'the', 'processing', 'steps', 'covered', 'in', 'this', 'section', 'are', 'commonly', 'used', 'in', 'NLP', 'and', 'involve', 'the', 'combination', 'of', 'several', 'steps', 'into', 'a', 'single', 'executable', 'flow', '.'], ['This', 'is', 'usually', 'referred', 'to', 'as', 'the', 'NLP', 'pipeline', '.'], ['These', 'flow', 'can', 'be', 'a', 'combination', 'of', 'tokenization', ',', 'stemming', ',', 'word', 'frequency', ',', 'parts', 'of', 'speech', 'tagging', ',', 'etc', '.']]\n",
            "POS are:  [[('Dealing', 'VBG'), ('with', 'IN'), ('textual', 'JJ'), ('data', 'NNS'), ('is', 'VBZ'), ('very', 'RB'), ('crucial', 'JJ'), ('so', 'RB'), ('to', 'TO'), ('handle', 'VB'), ('these', 'DT'), ('text', 'JJ'), ('data', 'NN'), ('we', 'PRP'), ('need', 'VBP'), ('some', 'DT'), ('basic', 'JJ'), ('text', 'NN'), ('processing', 'NN'), ('steps', 'NNS'), ('.', '.')], [('Most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('processing', 'NN'), ('steps', 'NNS'), ('covered', 'VBN'), ('in', 'IN'), ('this', 'DT'), ('section', 'NN'), ('are', 'VBP'), ('commonly', 'RB'), ('used', 'VBN'), ('in', 'IN'), ('NLP', 'NNP'), ('and', 'CC'), ('involve', 'VB'), ('the', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('several', 'JJ'), ('steps', 'NNS'), ('into', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('executable', 'JJ'), ('flow', 'NN'), ('.', '.')], [('This', 'DT'), ('is', 'VBZ'), ('usually', 'RB'), ('referred', 'VBN'), ('to', 'TO'), ('as', 'IN'), ('the', 'DT'), ('NLP', 'NNP'), ('pipeline', 'NN'), ('.', '.')], [('These', 'DT'), ('flow', 'NN'), ('can', 'MD'), ('be', 'VB'), ('a', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('tokenization', 'NN'), (',', ','), ('stemming', 'VBG'), (',', ','), ('word', 'NN'), ('frequency', 'NN'), (',', ','), ('parts', 'NNS'), ('of', 'IN'), ('speech', 'NN'), ('tagging', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]]\n",
            "POS pattern :  [['VBG', 'IN', 'JJ', 'NNS', 'VBZ', 'RB', 'JJ', 'RB', 'TO', 'VB', 'DT', 'JJ', 'NN', 'PRP', 'VBP', 'DT', 'JJ', 'NN', 'NN', 'NNS', '.'], ['JJS', 'IN', 'DT', 'NN', 'NNS', 'VBN', 'IN', 'DT', 'NN', 'VBP', 'RB', 'VBN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'JJ', 'JJ', 'NN', '.'], ['DT', 'VBZ', 'RB', 'VBN', 'TO', 'IN', 'DT', 'NNP', 'NN', '.'], ['DT', 'NN', 'MD', 'VB', 'DT', 'NN', 'IN', 'NN', ',', 'VBG', ',', 'NN', 'NN', ',', 'NNS', 'IN', 'NN', 'NN', ',', 'FW', '.']]\n",
            "Extracted nouns are:  [['data', 'data', 'text', 'processing', 'steps'], ['processing', 'steps', 'section', 'NLP', 'combination', 'steps', 'flow'], ['NLP', 'pipeline'], ['flow', 'combination', 'tokenization', 'word', 'frequency', 'parts', 'speech', 'tagging']]\n",
            "Extracted verbs are:  [['Dealing', 'is', 'handle', 'need'], ['covered', 'are', 'used', 'involve'], ['is', 'referred'], ['be', 'stemming']]\n"
          ]
        }
      ],
      "source": [
        "print (\"Sentences are:\", sentenses)\n",
        "print (\"Words are: \", words)\n",
        "print (\"POS are: \", tagged_wt)\n",
        "print (\"POS pattern : \",patternPOS)\n",
        "print (\"Extracted nouns are: \",nouns)\n",
        "print (\"Extracted verbs are: \",verbs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 829,
          "status": "ok",
          "timestamp": 1527106606645,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "zQuWyFPDPGAM",
        "outputId": "d5f56023-9272-4d14-fc67-3b269f871c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noun           Count\n",
            "-----------  -------\n",
            "step               3\n",
            "datum              2\n",
            "text               2\n",
            "processing         2\n",
            "combination        2\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "noun_counter = Counter(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n",
        "\n",
        "print(tabulate(noun_counter.most_common(5), headers=['Noun', 'Count']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VN6Cd2o5qYfs"
      },
      "source": [
        "# Dependency parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 816,
          "status": "ok",
          "timestamp": 1527106607535,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "-vSkHsFyPI_B",
        "outputId": "6b935879-a567-4bfc-e1df-e6dc8fd6d43e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"39743592ec7c4d9d9c18dd28fe5d28cf-0\" class=\"displacy\" width=\"1310\" height=\"347.0\" direction=\"ltr\" style=\"max-width: none; height: 347.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">usually</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">referred</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">as</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1030\">NLP</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1030\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">pipeline.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-0\" stroke-width=\"2px\" d=\"M70,212.0 C70,2.0 470.0,2.0 470.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,214.0 L62,202.0 78,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-1\" stroke-width=\"2px\" d=\"M210,212.0 C210,72.0 465.0,72.0 465.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M210,214.0 L202,202.0 218,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-2\" stroke-width=\"2px\" d=\"M350,212.0 C350,142.0 460.0,142.0 460.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M350,214.0 L342,202.0 358,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-3\" stroke-width=\"2px\" d=\"M490,212.0 C490,142.0 600.0,142.0 600.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M600.0,214.0 L608.0,202.0 592.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-4\" stroke-width=\"2px\" d=\"M490,212.0 C490,72.0 745.0,72.0 745.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,214.0 L753.0,202.0 737.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-5\" stroke-width=\"2px\" d=\"M910,212.0 C910,72.0 1165.0,72.0 1165.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910,214.0 L902,202.0 918,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-6\" stroke-width=\"2px\" d=\"M1050,212.0 C1050,142.0 1160.0,142.0 1160.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1050,214.0 L1042,202.0 1058,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-7\" stroke-width=\"2px\" d=\"M770,212.0 C770,2.0 1170.0,2.0 1170.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39743592ec7c4d9d9c18dd28fe5d28cf-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170.0,214.0 L1178.0,202.0 1162.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "doc = nlp(sentenses[2])\n",
        "spacy.displacy.render(doc,style='dep', options={'distance' : 140}, jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMJrQ1e1qeco"
      },
      "source": [
        "# Name Entity Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 821,
          "status": "ok",
          "timestamp": 1527106608430,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "LYyUwUcjokUJ",
        "outputId": "d22557a1-4cb2-4a98-9e2a-65e86f28efb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entity    Entity Type\n",
            "--------  -------------\n",
            "NLP       ORG\n",
            "\n",
            "Token        IOB Annotation    Entity Type\n",
            "-----------  ----------------  -------------\n",
            "Most         O\n",
            "of           O\n",
            "the          O\n",
            "processing   O\n",
            "steps        O\n",
            "covered      O\n",
            "in           O\n",
            "this         O\n",
            "section      O\n",
            "are          O\n",
            "             O\n",
            "commonly     O\n",
            "used         O\n",
            "in           O\n",
            "NLP          B                 ORG\n",
            "and          O\n",
            "involve      O\n",
            "the          O\n",
            "combination  O\n",
            "of           O\n",
            "several      O\n",
            "steps        O\n",
            "into         O\n",
            "a            O\n",
            "single       O\n",
            "             O\n",
            "executable   O\n",
            "flow         O\n",
            ".            O\n"
          ]
        }
      ],
      "source": [
        "# doc = nlp(\"Jill laughed at John Johnson.\")\n",
        "doc = nlp(sentenses[1])\n",
        "entity_types = ((ent.text, ent.label_) for ent in doc.ents)\n",
        "print(tabulate(entity_types, headers=['Entity', 'Entity Type']))\n",
        "print()\n",
        "token_entity_info = ((token.text, token.ent_iob_, token.ent_type_,) for token in doc)\n",
        "print(tabulate(token_entity_info, headers=['Token', 'IOB Annotation', 'Entity Type']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 899,
          "status": "ok",
          "timestamp": 1527106609402,
          "user": {
            "displayName": "RAHUL KUMAR",
            "photoUrl": "//lh5.googleusercontent.com/-Tsfm_ry7qgQ/AAAAAAAAAAI/AAAAAAAAIZs/NIipKd39rF4/s50-c-k-no/photo.jpg",
            "userId": "113791344848346830729"
          },
          "user_tz": -330
        },
        "id": "IrG35gj4qtNE",
        "outputId": "9908c468-80ed-4343-c27d-2447d2eb030d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entity    Entity Type\n",
            "--------  -------------\n",
            "Jack      PERSON\n",
            "India     GPE\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(u\"My name is Jack and I live in India.\")\n",
        "\n",
        "entity_types = ((ent.text, ent.label_) for ent in doc.ents)\n",
        "print(tabulate(entity_types, headers=['Entity', 'Entity Type']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "default_view": {},
      "name": "Chapter 4.ipynb",
      "provenance": [],
      "version": "0.3.2",
      "views": {}
    },
    "kernelspec": {
      "display_name": "PYTHONDEEPLEARNING",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b95616a71bdc1e80c800533f03a8b63e4e500e58b47a4c07f86675652d0e8884"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
